{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shoumik29/Parallel-Processing-and-Distributed-System-Lab/blob/main/CUDA_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KaOZMKoDqMi",
        "outputId": "e06c7cfe-3e2b-40ee-aa61-562ffa2adf0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jan 19 18:49:43 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NLd4HhjES8G",
        "outputId": "06501e9c-7ded-4ec3-ca35-febcb553ae8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLhvruf_HRCv",
        "outputId": "6c935914-112d-4f65-da74-9e0005780c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-krg0y5j7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-krg0y5j7\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0d2ab99cccbbc682722e708515fe9c4cfc50185a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fGKMjBuHjwi",
        "outputId": "8ddf5187-a13f-4e0a-8014-52a95a11b7b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#define K 2\n",
        "#define M 4\n",
        "#define N 4\n",
        "#define P 4\n",
        "\n",
        "void init_mat(int *mat, int a, int b){\n",
        "    for(int k=0;k<K;k++){\n",
        "        for(int i=0;i<a*b;i++) mat[k*M*N+i] = rand()%10;\n",
        "    }\n",
        "}\n",
        "\n",
        "void print_mat(int *mat, int a, int b, int indx){\n",
        "    for(int i=0;i<a;i++){\n",
        "        for(int j=0;j<b;j++) printf(\"%d \", mat[(indx*K)+(i*b)+j]);\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "}\n",
        "\n",
        "//kernel\n",
        "__global__ void matmul(int *a, int *b, int *c){\n",
        "\n",
        "    int z = blockIdx.x;\n",
        "    int x = threadIdx.x;\n",
        "    int y = threadIdx.y;\n",
        "\n",
        "    int c1 = M;\n",
        "    int c2 = P;\n",
        "    int c3 = K;\n",
        "\n",
        "    c[(z*c3)+(x*c2)+y] = 0;\n",
        "    for(int q=0;q<c1;q++){\n",
        "      c[(z*c3)+(x*c2)+y] = c[(z*c3)+(x*c2)+y] + (a[(z*c3)+(x*c2)+q] * b[(z*c3)+(q*c2)+y]);\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "\n",
        "    int mat_a[K*M*N];\n",
        "    int mat_b[K*N*P];\n",
        "    int mat_c[K*M*P];\n",
        "\n",
        "    //Initializing matrices\n",
        "    init_mat(mat_a, M, N);\n",
        "    init_mat(mat_b, N, P);\n",
        "\n",
        "    print_mat(mat_a, M, N, 1);\n",
        "    printf(\"\\n\");\n",
        "    print_mat(mat_b, N, P, 1);\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    //device memory\n",
        "    int* d_a;\n",
        "    int* d_b;\n",
        "    int* d_c;\n",
        "\n",
        "    cudaMalloc((void**)&d_a, K*M*N*sizeof(int));\n",
        "    cudaMalloc((void**)&d_b, K*N*P*sizeof(int));\n",
        "    cudaMalloc((void**)&d_c, K*M*P*sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_a, mat_a, K*M*N*sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, mat_b, K*N*P*sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 grid_size(K);\n",
        "    dim3 block_size(M,P);\n",
        "\n",
        "    //Launch kernel\n",
        "    matmul<<<grid_size, block_size>>>(d_a, d_b, d_c);\n",
        "\n",
        "    cudaMemcpy(mat_c, d_c, K*M*P*sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    print_mat(mat_c, M, P, 1);\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvGlIB99Hmnu",
        "outputId": "85f9e79e-6b3e-4fd3-8fe6-0c0ea5817487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 5 3 5 \n",
            "6 2 9 1 \n",
            "2 7 0 9 \n",
            "3 6 0 6 \n",
            "\n",
            "9 7 3 6 \n",
            "1 2 9 3 \n",
            "1 9 4 7 \n",
            "8 4 5 0 \n",
            "\n",
            "111 106 103 78 \n",
            "73 131 77 105 \n",
            "97 64 114 33 \n",
            "81 57 93 36 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <string.h>\n",
        "#include <cuda_runtime.h>\n",
        "#define T 1000\n",
        "#define S 50\n",
        "\n",
        "\n",
        "typedef struct {\n",
        "    char name[S];\n",
        "    char phone[S];\n",
        "} Contact;\n",
        "\n",
        "\n",
        "//kernel\n",
        "__global__ void search_contact(Contact* contacts, const char* searchName, int* indx){\n",
        "\n",
        "    int i = threadIdx.x;\n",
        "    int st_len, searchName_len=0, contact_len=0;\n",
        "    for(int j=0;searchName[j]!='\\0';j++) searchName_len++;\n",
        "    for(int j=0;contacts[i].name[j]!='\\0';j++) contact_len++;\n",
        "    if(searchName_len <= contact_len) st_len = searchName_len;\n",
        "    else st_len = contact_len;\n",
        "    int flag = 1;\n",
        "    for(int j=0;j<st_len;j++){\n",
        "        if(searchName[j] != contacts[i].name[j]){\n",
        "            flag = 0;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "    if(searchName_len != contact_len) flag = 0;\n",
        "    if(flag==1){\n",
        "        indx[i] = i;\n",
        "    }\n",
        "    else{\n",
        "        indx[i] = -1;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "int main(){\n",
        "\n",
        "    Contact contacts[T];\n",
        "    char searchName[S] = \"Grace Taylor\";\n",
        "\n",
        "    const char* phonebookFile_1 = \"/content/sample_data/input.txt\";\n",
        "    const char* phonebookFile_2 = \"/content/sample_data/input_1.txt\";\n",
        "\n",
        "    int total_contacts = 0;\n",
        "\n",
        "    FILE* file_1 = fopen(phonebookFile_1, \"r\");\n",
        "    FILE* file_2 = fopen(phonebookFile_2, \"r\");\n",
        "\n",
        "    while(fscanf(file_1, \"%49[^,],%111[^\\n]\\n\", contacts[total_contacts].name, contacts[total_contacts].phone)!= EOF){\n",
        "        //printf(\"%s    %s\\n\", contacts[total_contacts].name, contacts[total_contacts].phone);\n",
        "        total_contacts += 1;\n",
        "    }\n",
        "    while(fscanf(file_2, \"%49[^,],%111[^\\n]\\n\", contacts[total_contacts].name, contacts[total_contacts].phone)!= EOF){\n",
        "        //printf(\"%s    %s\\n\", contacts[total_contacts].name, contacts[total_contacts].phone);\n",
        "        total_contacts += 1;\n",
        "    }\n",
        "\n",
        "    fclose(file_1);\n",
        "    fclose(file_2);\n",
        "\n",
        "    //device memory\n",
        "    Contact* d_contacts;\n",
        "    char* d_searchName;\n",
        "    int* d_indx;\n",
        "\n",
        "    int t = total_contacts;\n",
        "\n",
        "    cudaMalloc((void**)&d_contacts, sizeof(Contact)*t);\n",
        "    cudaMalloc((void**)&d_searchName, S*sizeof(char));\n",
        "    cudaMalloc((void**)&d_indx, sizeof(int)*t);\n",
        "\n",
        "    cudaMemcpy(d_contacts, contacts, sizeof(Contact)*t, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_searchName, searchName, sizeof(char)*S, cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 grid_size(1);\n",
        "    dim3 block_size(t);\n",
        "\n",
        "    search_contact<<<grid_size, block_size>>>(d_contacts, d_searchName, d_indx);\n",
        "\n",
        "    int indx[t]={0};\n",
        "    cudaMemcpy(indx, d_indx, sizeof(int)*t, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    int nf = 0;\n",
        "    for(int y=0;y<t;y++){\n",
        "      if(indx[y]>=0){\n",
        "        nf = 0;\n",
        "        printf(\"%s  %s\\n\", contacts[indx[y]].name, contacts[indx[y]].phone);\n",
        "        break;\n",
        "      }\n",
        "      else nf = 1;\n",
        "    }\n",
        "    if(nf) printf(\"Not Found\\n\");\n",
        "\n",
        "    cudaFree(d_contacts);\n",
        "    cudaFree(d_indx);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "zZVNV-657nur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be234cbf-88a3-4190-e154-5ceaa9be9df8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grace Taylor  7890123456\n",
            "\n"
          ]
        }
      ]
    }
  ]
}